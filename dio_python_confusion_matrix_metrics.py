# -*- coding: utf-8 -*-
"""dio-python-confusion-matrix-metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o6EKvOZNRZ9nHf_nOyGBTuHwDjYkVO6q

Utilizado como base o seguinte notebook:

https://colab.research.google.com/drive/1S9ThhinDflxU4KmTdxcv6_mE_vWwk2Jk#scrollTo=Nr2ZyMJk9bbn
"""

!pip install --no-cache-dir -q tensorflow-gpu==2.8.0

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import tensorflow as tf

import numpy as np

import seaborn as sns

import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

logdir='log'

(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))

train_images, test_images = train_images / 255.0, test_images / 255.0

classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x=train_images,
            y=train_labels,
            epochs=5,
            validation_data=(test_images, test_labels))

y_true=test_labels
# y_pred=model.predict_classes(test_images)

# Use model.predict and np.argmax to get predicted classes
y_pred = np.argmax(model.predict(test_images), axis=-1)

# Para cálculo das métricas
y_pred_classes = y_pred

classes=[0,1,2,3,4,5,6,7,8,9]

con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()
con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

con_mat_df = pd.DataFrame(con_mat_norm,
                     index = classes,
                     columns = classes)

figure = plt.figure(figsize=(8, 8))
sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

model1 = models.Sequential()
model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model1.add(layers.MaxPooling2D((2, 2)))
model1.add(layers.Conv2D(64, (3, 3), activation='relu'))
model1.add(layers.MaxPooling2D((2, 2)))
model1.add(layers.Conv2D(64, (3, 3), activation='relu'))

model1.add(layers.Flatten())
model1.add(layers.Dense(64, activation='relu'))
model1.add(layers.Dense(10, activation='softmax'))

model1.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

import io

file_writer = tf.summary.create_file_writer(logdir + '/cm')

def log_confusion_matrix(epoch, logs):
  # Use the model to predict the values from the validation dataset.

  #test_pred = model1.predict_classes(test_images)
  test_pred = np.argmax(model.predict(test_images), axis=-1)

  con_mat = tf.math.confusion_matrix(labels=test_labels, predictions=test_pred).numpy()
  con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

  con_mat_df = pd.DataFrame(con_mat_norm,
                     index = classes,
                     columns = classes)

  figure = plt.figure(figsize=(8, 8))
  sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)
  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')

  buf = io.BytesIO()
  plt.savefig(buf, format='png')

  plt.close(figure)
  buf.seek(0)
  image = tf.image.decode_png(buf.getvalue(), channels=4)

  image = tf.expand_dims(image, 0)

  # Log the confusion matrix as an image summary.
  with file_writer.as_default():
    tf.summary.image("Matriz de confusão", image, step=epoch)


logdir='logs/images'

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)

cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)

model1.fit(
    train_images,
    train_labels,
    epochs=5,
    verbose=0,
    callbacks=[tensorboard_callback, cm_callback],
    validation_data=(test_images, test_labels),
)

# Commented out IPython magic to ensure Python compatibility.
# Start TensorBoard.
# %tensorboard --logdir logs/images

#Cálculo das métricas

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(test_labels, y_pred_classes)
false_positives = np.sum(cm[:, 1]) - cm[1, 1]
false_negatives = np.sum(cm[1, :]) - cm[1, 1]  # Assuming class 1 is the positive class
true_negatives = np.sum(cm) - (np.sum(cm[:, 1]) + np.sum(cm[1, :]) - cm[1, 1])
true_positives = cm[1, 1]

print("Falsos positivos:", false_positives)
print("Falsos negativos:", false_negatives)
print("Verdadeiros negativos::", true_negatives)
print("Verdadeiros positivos:", true_positives)
num_params = false_positives + false_negatives + true_negatives + true_positives
print("Total de elementos:", num_params)
sensitivity = true_positives / (true_positives + false_negatives)
print("Sensibilidade:", sensitivity)
print("Especificidade:", true_negatives / (true_negatives + false_positives))
precision = true_positives / (true_positives + false_positives)
print("Precisão:", precision)
print("Acurácia:", (true_positives + true_negatives) / num_params)
print("F1 Score:", 2 * ((precision * sensitivity) / (precision + sensitivity)))